\section{Datenaufbereitung und Transkription}

Die Audioaufnahmen der Interviews werden vollständig transkribiert, um das Datenmaterial für die qualitative Inhaltsanalyse zugänglich zu machen. Die Transkription folgt den Regeln des einfachen Transkriptionssystems nach \textcite{dresingTranskriptionenQualitativerDaten2017}, das für inhaltsanalytische Auswertungsverfahren empfohlen wird. Dieses System priorisiert semantische Genauigkeit gegenüber phonetischer Detailtreue: Dialektfärbungen werden ins Hochdeutsche übertragen, Wort- und Satzabbrüche dokumentiert, Pausen ab drei Sekunden markiert und nonverbale Äußerungen (Lachen, Zögern) in Klammern notiert. Auf eine Notation von Intonationsverläufen oder exakten Pausenlängen wird verzichtet, da die Analyse auf inhaltliche Deutungsmuster abzielt, nicht auf konversationsanalytische Feinstrukturen \parencite{flick2017}.

Die Transkription erfolgt softwaregestützt. Zunächst wird eine automatische Rohtranskription erstellt, die anschließend manuell anhand der Originalaufnahme korrigiert und den Transkriptionsregeln angepasst wird. Jedes Transkript wird vollständig mit der Aufnahme abgeglichen, um Übertragungsfehler auszuschließen. Zeitmarken werden in regelmäßigen Abständen gesetzt, um die Zuordnung von Textstellen zur Aufnahme zu ermöglichen.

Im Zuge der Transkription werden sämtliche identifizierenden Merkmale pseudonymisiert: Namen der Interviewpartner:innen, Institutionen, Standorte und spezifische Funktionsbezeichnungen werden durch neutrale Kürzel ersetzt (z.\,B. \textit{IP-01}, \textit{Bank-A}). Rückschlüsse auf Einzelpersonen oder Organisationen werden durch Verallgemeinerung oder gezielte Auslassung spezifischer Details verhindert. Die Pseudonymisierungslogik wird in einem separaten, passwortgeschützten Schlüsseldokument dokumentiert, das ausschließlich dem Verfasser zugänglich ist.

Nach Abschluss der Transkription und Validierung werden die fertiggestellten Transkripte den jeweiligen Interviewpartner:innen zur optionalen Durchsicht angeboten (\textit{Member Check}). Dieser Schritt dient nicht der Verifizierung der Analyse, sondern der Absicherung, dass die dokumentierte Gesprächsbasis korrekt und vollständig ist \parencite{flick2017}.


\section{Datenauswertung: Strukturierende qualitative Inhaltsanalyse}

Die Auswertung des Interviewmaterials folgt der inhaltlich-strukturierenden qualitativen Inhaltsanalyse nach Kuckartz, die deduktive Kategorienarbeit mit induktiver Offenheit für unerwartete Muster verbindet. Der folgende Abschnitt stellt die methodische Grundlage vor, operationalisiert die deduktiven Hauptkategorien und beschreibt das Vorgehen bei der induktiven Subkategorienbildung.

\subsection{Methodische Grundlage}

Für die Auswertung des Interviewmaterials wird die inhaltlich-strukturierende qualitative Inhaltsanalyse nach \textcite{kuckartz_qualitative_2018} eingesetzt. Diese Methode eignet sich für die vorliegende Arbeit aus mehreren Gründen: Sie ermöglicht eine theoriegeleitete, systematische Auswertung entlang vorgegebener Kategorien, ist aber gleichzeitig offen für induktive Ergänzungen aus dem Material. Damit verbindet sie die Stärken deduktiver Strukturierung mit der Fähigkeit, unerwartete Muster zu entdecken -- eine Eigenschaft, die angesichts des explorativen Charakters der Forschungsfrage zentral ist.

Das Verfahren unterscheidet sich von der qualitativen Inhaltsanalyse nach Mayring, mit der es häufig verwechselt wird. Während \textcite{mayring2016} stärker regelgeleitet und sequenziell vorgeht, betont Kuckartz den iterativen Charakter des Analyseprozesses und die Verschränkung von Fallarbeit und Kategorienarbeit \parencite{kuckartz_qualitative_2018}. Die Analyseschritte verlaufen nicht streng linear, sondern zirkulär: Kategorien werden im Laufe der Auswertung verfeinert, zusammengelegt oder ausdifferenziert.

Der Analyseprozess folgt sieben Phasen \parencite{kuckartz_qualitative_2018}:

\begin{enumerate}
    \item \textbf{Initiierende Textarbeit:} Sorgfältiges Lesen aller Transkripte, Markierung auffälliger Passagen, Verfassen von Memos zu ersten Eindrücken und Deutungen.
    \item \textbf{Entwicklung thematischer Hauptkategorien:} Ableitung der deduktiven Kategorien aus dem theoretischen Rahmen (hier: \acrshort{sdt}-Grundbedürfnisse).
    \item \textbf{Erster Codierdurchgang:} Codierung des gesamten Materials entlang der Hauptkategorien. Jede Textstelle wird der passenden Kategorie zugeordnet; Mehrfachcodierungen sind zulässig.
    \item \textbf{Zusammenstellung aller codierten Textstellen:} Systematische Zusammenführung aller einer Kategorie zugeordneten Textstellen.
    \item \textbf{Induktive Ausdifferenzierung:} Bildung von Subkategorien am Material, die das deduktive Kategoriensystem ergänzen und verfeinern.
    \item \textbf{Zweiter Codierdurchgang:} Erneute Codierung des gesamten Materials mit dem ausdifferenzierten Kategoriensystem.
    \item \textbf{Analyse und Ergebnisdarstellung:} Kategorienbasierte und fallübergreifende Auswertung, Identifikation von Mustern und Zusammenhängen.
\end{enumerate}

Die Codierung erfolgt softwaregestützt mit MAXQDA, das für qualitative Inhaltsanalysen nach Kuckartz explizit konzipiert ist und Funktionen für Codierung, Memo-Verwaltung, Kategorienvergleich und visuelle Analyse bereitstellt.


\subsection{Deduktive Hauptkategorien (SDT-Grundbedürfnisse)}

Die drei psychologischen Grundbedürfnisse der \gls{sdt} bilden das deduktive Kategoriensystem der Analyse. Dieses Vorgehen begründet sich theoretisch: \gls{sdt} postuliert, dass Autonomie, Kompetenz und soziale Eingebundenheit als universelle Grundbedürfnisse die zentralen Mechanismen motivationalen Erlebens darstellen (vgl. Abschnitt 2.3). Die Fragestellung der Arbeit richtet sich explizit auf diese drei Dimensionen; ein deduktiver Einstieg ist daher methodologisch konsistent und nicht willkürlich.

Die Hauptkategorien werden wie folgt operationalisiert:

\paragraph{HK1 -- Autonomieerleben.} Textstellen, in denen Interviewpartner:innen beschreiben, wie der Einsatz generativer \gls{ki} ihr Erleben von Selbstbestimmung, Entscheidungsfreiheit und Handlungsspielraum beeinflusst. Dazu zählen sowohl autonomieförderliche Erfahrungen (erweiterte Gestaltungsspielräume, Entlastung von fremdbestimmten Aufgaben) als auch autonomiefrustrierende Erfahrungen (algorithmische Kontrolle, Einengung von Entscheidungskorridoren, erlebter Zwang zur \acrshort{ki}-Nutzung).

\paragraph{HK2 -- Kompetenzerleben.} Textstellen, in denen Interviewpartner:innen beschreiben, wie generative \gls{ki} ihr Erleben von Wirksamkeit, Expertise und professioneller Kompetenz beeinflusst. Dies umfasst kompetenzförderliche Erfahrungen (erweiterte Fähigkeiten, neue Kompetenzdomänen, verbesserte Ergebnisqualität) und kompetenzfrustrierende Erfahrungen (Expertiseentwertung, Attributionsverschiebung, Überforderung durch neue Anforderungen).

\paragraph{HK3 -- Soziale Eingebundenheit.} Textstellen, in denen Interviewpartner:innen beschreiben, wie generative \gls{ki} ihr Erleben von Zugehörigkeit, Beziehungsqualität und Wertschätzung im organisationalen Kontext beeinflusst. Dies umfasst Erfahrungen von veränderter Teaminteraktion, Rollenverschiebungen in der Führungsbeziehung, organisationaler Wertschätzung sowie neue Formen der Zusammenarbeit oder Isolation.

Ergänzend wird eine Restkategorie \textbf{HK0 -- Übergreifende Kontextfaktoren} geführt, die Textstellen aufnimmt, die für das Verständnis der motivationalen Dynamik relevant sind, aber keiner der drei Grundbedürfniskategorien eindeutig zugeordnet werden können -- etwa organisationale Rahmenbedingungen, regulatorische Kontexte oder biografische Einbettungen.


\subsection{Induktive Subkategorienbildung}

Die deduktiven Hauptkategorien werden im Verlauf der Analyse durch induktive Subkategorien ausdifferenziert. Das Ziel ist, die theoretische Struktur mit den tatsächlichen Erfahrungsmustern der Interviewpartner:innen zu verschränken und so über die bloße Bestätigung oder Widerlegung theoretischer Annahmen hinauszugehen.

Die Subkategorienbildung erfolgt nach Phase 4 des Analyseprozesses: Nachdem alle Textstellen den Hauptkategorien zugeordnet sind, werden die Textpassagen innerhalb jeder Kategorie systematisch gesichtet und nach wiederkehrenden Themen, Deutungsmustern und Erfahrungsdimensionen differenziert \parencite{kuckartz_qualitative_2018}. Die Subkategorien entstehen am Material, nicht aus theoretischen Vorannahmen -- wenngleich Sensibilisierung durch die SDT-Literatur und die in Kapitel 2 identifizierten Spannungsfelder (Kontrolle vs. Unterstützung, Expertiseentwertung vs. neue Kompetenzdomänen, Teaminteraktion vs. Individualisierung) die Aufmerksamkeit der Analyse lenkt.

Konkret ist folgender Prozess vorgesehen: Für jede Hauptkategorie werden die zugeordneten Textstellen fallübergreifend verglichen. Passagen mit ähnlicher inhaltlicher Aussage werden zu thematischen Clustern zusammengefasst und mit einem beschreibenden Label versehen. Diese vorläufigen Subkategorien werden anschließend geprüft: Überlappende Kategorien werden konsolidiert, zu breite aufgespalten, nicht tragfähige verworfen. Das resultierende Kategoriensystem wird in einem Codebuch mit Definitionen, Ankerbeispielen und Abgrenzungsregeln dokumentiert.

Um die interne Konsistenz der Codierung zu sichern, wird eine Teilmenge von [X]\,\% des Materials von einer zweiten Person unabhängig codiert (\textit{konsensuelle Codierung}). Abweichungen werden diskutiert und das Kategoriensystem gegebenenfalls angepasst \parencite{kuckartz_qualitative_2018}. Dieses Verfahren dient nicht der Berechnung von Intercoder-Reliabilität im quantitativen Sinne, sondern der reflexiven Qualitätssicherung.


\section{Gütekriterien qualitativer Forschung}

Qualitative Forschung folgt eigenen Gütekriterien, die sich von den quantitativen Maßstäben Reliabilität, Validität und Objektivität unterscheiden, ohne den Anspruch auf methodische Strenge aufzugeben \parencite{flick2017, mayring2016}. Die vorliegende Arbeit orientiert sich an den von \textcite{mayring2016} formulierten Qualitätskriterien qualitativer Forschung und ergänzt diese um spezifische Maßnahmen.

\paragraph{Verfahrensdokumentation.} Die Nachvollziehbarkeit des Forschungsprozesses wird durch lückenlose Dokumentation aller methodischen Entscheidungen sichergestellt: Forschungsdesign, Sampling-Strategie, Interviewleitfaden, Transkriptionsregeln, Kategoriensystem und Analyseschritte werden im Methodenkapitel offengelegt. Das Codebuch mit Kategoriendefinitionen, Ankerbeispielen und Codierregeln wird als Anhang bereitgestellt.

\paragraph{Argumentative Interpretationsabsicherung.} Interpretationen werden nicht bloß behauptet, sondern durch Ankerbeispiele aus dem Material belegt und theoretisch eingebettet. Alternative Deutungsmöglichkeiten werden systematisch geprüft und diskutiert. Die Ergebnisdarstellung in Kapitel 4 folgt dem Prinzip, Belege und Interpretation transparent zu verzahnen.

\paragraph{Regelgeleitetheit.} Die Analyse folgt dem systematischen Phasenmodell nach \textcite{kuckartz_qualitative_2018}. Codierregeln werden vorab definiert und im Prozess dokumentiert angepasst. Die Regelgeleitetheit wird durch den Einsatz von MAXQDA unterstützt, das die Codierhistorie nachvollziehbar macht.

\paragraph{Nähe zum Gegenstand.} Die Untersuchung orientiert sich an der Lebens- und Arbeitswelt der Befragten. Die problemzentrierten Interviews ermöglichen es, den Erfahrungshorizont der Interviewpartner:innen als Ausgangspunkt der Analyse zu nehmen, statt vorstrukturierte Antwortmuster abzufragen \parencite{witzelProblemcenteredInterview2000}. Der Interviewleitfaden wurde in Pretests geprüft und enthält erzählgenerierende Stimuli, die an konkreten Arbeitssituationen ansetzen.

\paragraph{Kommunikative Validierung.} Die fertiggestellten Transkripte werden den Interviewpartner:innen zur optionalen Durchsicht angeboten (Member Check). Darüber hinaus werden zentrale Analyseergebnisse im Betreuungsprozess diskutiert, um blinde Flecken der Interpretation zu identifizieren \parencite{flick2017}.

\paragraph{Triangulation.} Da die Arbeit ein monomethodisches Design verfolgt (ausschließlich problemzentrierte Interviews), ist eine Methodentriangulation im engeren Sinne nicht möglich. Stattdessen wird auf theoretische Triangulation gesetzt: Die Ergebnisse werden nicht nur im Licht der \gls{sdt}, sondern auch mit ergänzenden theoretischen Perspektiven (\acrshort{jdr}-Modell, Rollentheorie, Attributionstheorie) diskutiert, um eindimensionale Interpretationen zu vermeiden. Zudem ermöglicht das bewusst heterogene Sampling eine Perspektiventriangulation über unterschiedliche Institutionsgrößen, Tätigkeitsschwerpunkte und Länderkontexte hinweg.

\paragraph{Reflexivität.} Der Verfasser steht möglicherweise bei einzelnen Interviewpartner:innen in einem Beschäftigungsverhältnis beim gleichen Institut. Diese potenzielle Verzerrung durch berufliche Netzwerknähe wird durch reflektierte Interviewführung, transparente Offenlegung und die Dokumentation von Reflexionsmemos adressiert. Memos zu eigenen Vorannahmen, emotionalen Reaktionen und methodischen Entscheidungen werden während des gesamten Forschungsprozesses geführt und bei der Interpretation berücksichtigt \parencite{przyborski2021}.


\section{Ethische Überlegungen und Datenschutz}

Die Studie wurde dem MCI Ethics Assessment unterzogen und positiv begutachtet. Die ethischen Grundsätze orientieren sich an den Prinzipien informierter Einwilligung, Freiwilligkeit, Vertraulichkeit und Schadensvermeidung.

\paragraph{Informierte Einwilligung.} Alle Teilnehmer:innen erhalten vor dem Interview ein Informationsblatt mit Angaben zu Zweck, Ablauf, voraussichtlicher Dauer, Freiwilligkeit, Datenschutz und Anonymisierungsverfahren. Vor Beginn des Interviews wird eine schriftliche Einwilligungserklärung eingeholt, die explizit die Tonaufnahme umfasst. Die Teilnehmer:innen werden darauf hingewiesen, dass sie das Interview jederzeit und ohne Angabe von Gründen abbrechen können, ohne Nachteile zu erfahren. Einzelne Fragen können übersprungen werden.

\paragraph{Risikobewertung.} Das Forschungsthema -- Arbeitserfahrungen mit generativer KI -- birgt keine relevanten physischen Risiken. Psychologische Risiken sind gering, können aber nicht vollständig ausgeschlossen werden: Fragen zur Arbeitsplatzveränderung durch KI können Unsicherheiten berühren. Sollte ein:e Teilnehmer:in Unbehagen signalisieren, wird das Interview sensibel gesteuert und auf Wunsch abgebrochen.

\paragraph{Datenschutz und Datenspeicherung.} Audioaufnahmen und Transkripte werden ausschließlich auf verschlüsselten, passwortgeschützten Geräten und \acrshort{dsgvo}-konformen Cloud-Diensten gespeichert. Zugang haben ausschließlich der Verfasser und die betreuende Lehrperson. Alle personenbezogenen Angaben -- Namen, Institutionen, Standorte, spezifische Funktionsbezeichnungen -- werden im Transkript durch Pseudonyme ersetzt. Die Pseudonymisierungslogik wird in einem separaten Schlüsseldokument geführt, das nach Abschluss der Arbeit gelöscht wird.

\paragraph{Löschfristen.} Originalaufnahmen werden nach Abschluss der Transkription und Validierung durch die Teilnehmer:innen gelöscht, spätestens nach Abschluss der Arbeit (September 2026). Anonymisierte Transkripte werden für die Dauer der Archivierungspflicht aufbewahrt.

\paragraph{Rückmeldung.} Teilnehmer:innen, die eine Rückmeldung wünschen, erhalten nach Abschluss der Arbeit eine Zusammenfassung der zentralen Befunde.