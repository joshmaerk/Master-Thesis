\section{Generative KI in der Entscheidungsarbeit des mittleren Managements}

Generative KI-Systeme (etwa Large-Language-Model-basierte Assistenten wie ChatGPT) repräsentieren eine neue Klasse digitaler Arbeitssysteme. Im Unterschied zu klassischer IT und Automatisierung, die vornehmlich regelbasierte Routineprozesse ersetzt, können generative KI-Modelle eigenständig neue Inhalte erzeugen und in natürlicher Sprache interagieren. Dadurch verschiebt sich die Rolle der Technologie im Arbeitsprozess von einer rein ausführenden Maschine hin zu einem \textit{socio}-technischen \textit{Partner}, der menschliche Arbeit augmentiert statt sie zu substituieren. Aktuelle Management-Forschung betont entsprechend, dass die größten Produktivitätsgewinne durch ein bewusstes Zusammenwirken von Mensch und KI erzielt werden – KI soll die Fähigkeiten der Beschäftigten gezielt ergänzen, nicht ersetzen. So plädiert Brynjolfsson (2023) dafür, KI zur Unterstützung einzusetzen („augment“), anstatt menschliche Arbeitskräfte einfach zu automatisieren.

Diese Sicht steht im Spannungsfeld zu Stimmen, die das Disruptionspotenzial von KI für Managementaufgaben betonen. Van Quaquebeke und Gerpott (2023) argumentieren in einem vielbeachteten Meinungsbeitrag sogar, dass man die Unersetzlichkeit menschlicher Führung nicht \glqq romantisieren\grqq{} dürfe. Sie zeichnen ein Zukunftsbild, in dem fortgeschrittene KI-Systeme perspektivisch auch Kernbereiche von Leadership übernehmen könnten – möglicherweise sogar effektiver, was die Bedürfnisse der Mitarbeiter angeht, als menschliche Vorgesetzte. Tatsächlich besteht zunehmend Konsens, dass KI-Systeme in naher Zukunft viele standardisierte Managementaufgaben abdecken werden. Beispiele hierfür sind automatisierte Personalvorauswahl, Schicht- und Ressourceneinteilung oder Performancemessungen mittels Algorithmen. Allerdings bleibt \glqq echte\grqq{} zwischenmenschliche Führungsarbeit – das Motivieren, Entwickeln und Einbinden von Mitarbeitenden – bislang primär im menschlichen Verantwortungsbereich. Generative KI markiert hier einen neuartigen Grenzfall: Sie dringt durch ihre kognitiven und kommunikativen Fähigkeiten in Bereiche vor, die vormals als Domäne menschlicher Urteilskraft galten. Dies erfordert eine theoretische Verortung der Technologie als sozio-technisches Phänomen: Ihre Wirkung entfaltet sich in der Interaktion mit organisationalen Strukturen, kulturellen Deutungsmustern und menschlichen Kompetenzen, anstatt deterministisch durch die Technik allein vorgegeben zu sein.

\subsection{Generative KI als neue Klasse digitaler Arbeitssysteme (Augmentierung statt Automatisierung)}

Aus organisationsentwicklerischer Sicht lässt sich generative KI als \textit{neue Klasse digitaler Arbeitssysteme} begreifen, die sich deutlich von früheren IT-Anwendungen unterscheiden. Klassische Informationssysteme und Automatisierungstechnologien waren in der Regel darauf ausgerichtet, wohldefinierte Abläufe effizienter oder fehlerfreier auszuführen. Demgegenüber basieren generative KI-Systeme auf lernenden Algorithmen und großen vortrainierten Modellen, die in unstrukturierten Problemsituationen eingesetzt werden können. Sie erkennen Muster in umfangreichen Daten, generieren Vorhersagen oder Inhalte und passen sich durch Nutzerfeedback an. Damit können sie Aufgaben übernehmen, die zu komplex oder kreativ für starre Automatismen sind – etwa das Entwerfen von Textentwürfen, Bildern oder Entscheidungsoptionen.

Wichtig ist, dass generative KI primär eine \textit{ergänzende} Funktion einnimmt. In der aktuellen Literatur wird dies unter dem Leitbild der \textit{Augmentierung} diskutiert. So betont ein systematischer Review von Bankins et al. (2024), dass die produktiven Effekte von KI nur durch ein intentionales Zusammenwirken von Mensch und Maschine realisiert werden können. KI-Anwendungen sollen demnach menschliche Arbeit komplementieren – sie zielen darauf ab, die Leistung, Fähigkeiten oder Entscheidungsgrundlagen von Personen zu erweitern, anstatt Menschen vollständig zu ersetzen. Beispiele dafür sind digitale Assistenten, die Entscheidungsträgern in Echtzeit Datenanalyse-Ergebnisse liefern, oder generative Sprachmodelle, die Manager bei der Erstellung von Berichten und Präsentationen unterstützen. Solche KI-Tools können etwa bei der Verbesserung von Entscheidungsfindung helfen, indem sie strukturierte Empfehlungen oder Mustererkennungen liefern, welche die menschliche Urteilsbildung entlasten.

Theoretisch knüpft diese augmentierende Rolle von KI an Ansätze wie das \textit{Automation–Augmentation}-Paradigma an (vgl. Raisch & Krakowski, 2021). Demnach treten Automatisierung (Maschine übernimmt eine Aufgabe vollständig) und Augmentierung (Maschine unterstützt den Menschen) nicht als strikte Gegensätze auf, sondern müssen im Management dynamisch ausbalanciert werden. Generative KI veranschaulicht dieses Spannungsfeld deutlich: Einerseits vermag sie bestimmte Arbeitsschritte (z.,B. Informationsaggregation) eigenständig zu erledigen, andererseits bleibt sie auf menschliche Anleitung, Kontextwissen und Qualitätskontrolle angewiesen. Insofern entstehen durch generative KI hybride Arbeitssysteme, in denen Aufgaben zwischen Mensch und KI neu verteilt werden. Forschungsergebnisse zeigen, dass solche hybriden Systeme erfolgreich sind, wenn sich die Stärken beider Seiten ergänzen: Routineaufgaben und Big-Data-Analysen werden der KI überlassen, während menschliche Entscheidungsträger sich auf komplexe Urteilsfindung, ethische Abwägungen und kreative Problemlösung konzentrieren. Ein praktisches Beispiel liefert Brynjolfsson (2023), der in einer Stanford-HAI-Studie fordert, KI gezielt einzusetzen, um menschliche Fähigkeiten zu steigern, statt nur Kosteneinsparungen durch Stellenabbau zu suchen. Diese \glqq Mensch-KI-Kollaboration\grqq{} bildet den Kern der Vision \glqq augmented workforce\grqq{}, bei der Mitarbeiter und KI-Systeme als Team interagieren. Erste Studien untermauern die Machbarkeit: So berichten Nguyen und Malik (2022), dass Arbeitnehmer, die eine gute Passung zwischen ihren Aufgaben und den KI-Funktionen wahrnehmen, sowohl höhere Zufriedenheit als auch Produktivitätszuwächse verzeichnen. Voraussetzung dafür ist allerdings, dass die Nutzer der KI vertrauen, ihren Zweck verstehen und die nötigen Fähigkeiten zu ihrer Bedienung aufbauen. Kurz: Generative KI entfaltet ihr Potential am besten in einem sozio-technischen Arbeitsdesign, das Mensch und Maschine komplementär verzahnt.

\subsection{Einsatz generativer KI in der Entscheidungsvorbereitung des mittleren Managements}

Die mittlere Führungsebene nimmt in Entscheidungsprozessen eine Schlüsselrolle ein: Sie sammelt Informationen, bereitet strategische Entscheidungen für das Top-Management vor und trifft selbst operative Teilentscheidungen. Die Nutzung generativer KI bietet hier erhebliche Chancen, diese \textit{Entscheidungsvorbereitung} effizienter und fundierter zu gestalten. Insbesondere entlastet KI bei der Bewältigung großer Informationsmengen und bei der Entwicklung von Entscheidungsoptionen. So können moderne KI-Systeme unstrukturierte Daten (z.,B. Berichtstexte, Marktinformationen) in kürzester Zeit analysieren und verdichten. Ein KI-Assistenzsystem kann etwa innerhalb von Sekunden aus einer Flut von Dokumenten die wichtigsten Fakten extrahieren oder verschiedene Szenarien für eine Entscheidung durchrechnen und sprachlich aufbereiten. Für Manager im mittleren Management, die häufig unter hohem Zeitdruck komplexe Lagebilder für Vorgesetzte aufbereiten müssen, ist dies ein wertvoller Vorteil.

Empirische Befunde untermauern die zunehmende Verbreitung solcher Anwendungen. Bankins et al. (2024) stellen fest, dass KI inzwischen in vielfältigen Funktionen eingesetzt wird, um Entscheidungsprozesse zu unterstützen – von digitalen Assistenten bis hin zur Entscheidungsanalyse. Konkrete Branchenbeispiele zeigen die Dimension des Wandels: In der Finanzdienstleistung etwa werden heute bereits rund 90,% der standardisierten Kreditentscheidungen durch KI-Systeme getroffen, was von mittleren Managern ein Umdenken ihrer eigenen Aufgaben verlangt. Wo früher Abteilungsleiter Kreditprüfungen manuell vornahmen, überwachen sie nun eher die von Algorithmen getroffenen Entscheidungen und kümmern sich verstärkt um Ausnahmefälle oder Kundenkommunikation. Diese Verschiebung weg von Routineprüfungen hin zu überwachter Entscheidungsfindung illustriert, wie generative KI die inhaltliche Arbeit des mittleren Managements neu definiert, anstatt sie obsolet zu machen.

Mehrere Autoren betonen in diesem Zusammenhang, dass generative KI vor allem die Arbeitsinhalte der mittleren Führungskräfte verändert, nicht aber ihren grundsätzlichen Wertbeitrag eliminiert. So wird argumentiert, KI nehme Mittelmanagern repetitive, datenintensive Aufgaben ab, wodurch diese ihre Kapazität auf höherwertige Aktivitäten verlagern können – etwa auf Interpretations-, Coaching- und Koordinationsaufgaben. Rezente Literatur skizziert bereits neue Rollenbilder für KI-augmentierte Manager. Kurtulush et al. (2025) etwa formulieren einen Rahmen, in dem traditionelle Rollen des Mittleren Managements (z.,B. Administrator, Kommunikator, Informationsverteiler) um neue KI-bezogene Rollen erweitert werden. Ein \glqq AI Orchestrator\grqq{}-Manager beispielsweise versteht es, verschiedene KI-Tools im Team effektiv einzusetzen und ihre Outputs zu einem Gesamtbild zu orchestrieren. Der \glqq Meaning Maker\grqq{} (Sinnstifter) interpretiert die von KI generierten Analysen im spezifischen Unternehmenskontext und leitet daraus verständliche Handlungsimplikationen ab. Als \glqq Ethical Guardian\grqq{} achtet die Führungskraft darauf, dass KI-Empfehlungen ethisch und regulatorisch vertretbar sind, und als \glqq Strategic Coach\grqq{} fördert sie die Kompetenzen der Mitarbeiter im Umgang mit KI, um gemeinsam bessere Entscheidungen zu treffen. Diese neuen Rollen unterstreichen: Der Einsatz generativer KI ersetzt die Aufgaben des mittleren Managements nicht, sondern transformiert sie. Die Führungskraft wird zum Vermittler zwischen KI-Output und organisationaler Realität – einer Art \textit{Brückeninstanz}, die sicherstellt, dass die technischen Möglichkeiten in sinnvolle Entscheidungen übersetzt werden.

Theoretisch lässt sich dieser Wandel als Erweiterung des Entscheidungskonzepts verstehen: Entscheidungen entstehen nicht mehr allein aus menschlicher Analyse, sondern im \textit{Teamwork} mit einer KI. Einige Autoren sprechen hier von augmented decision making, also erweiterten Entscheidungsprozessen, in denen KI-basierte Analysesysteme dem Menschen zuarbeiten. Erste Studien deuten an, dass solche hybriden Entscheidungen qualitativ hochwertig sein können – insbesondere, wenn die KI die menschliche Urteilsfindung mit objektiven Datenmustern und vielfältigen Lösungsansätzen bereichert, der Mensch aber weiterhin seine Erfahrung und Kontextkenntnis einbringt (Meijer et al., 2021; van den Broek et al., 2021). Wichtig ist daher, dass mittlere Manager neue Kompetenzen entwickeln, um KI-Outputs kritisch zu prüfen und zu interpretieren. Anstatt blind den Vorschlägen der Maschine zu folgen, müssen sie gezielt Fragen stellen wie: \glqq Welche Annahmen liegen der Empfehlung der KI zugrunde?\grqq{} oder \glqq Welche Risiken könnten mit diesem vom Modell vorgeschlagenen Szenario verbunden sein?\grqq{} – und bei Bedarf gegensteuern. Damit rückt die menschliche Urteilskraft als Erfolgsfaktor noch stärker in den Vordergrund. Dies bestätigt auch eine Untersuchung von Deloitte (2025): In einer Arbeitswelt, in der technische Routinetätigkeiten zunehmend von KI erledigt werden, wird die Fähigkeit der Manager, Urteilsvermögen anzuwenden, zum entscheidenden Differenzierungsmerkmal. Unter Urteilsvermögen versteht man hier die Kunst, in unübersichtlichen Situationen gut begründete Entscheidungen zu treffen, indem man implizites Organisationswissen, Empathie und ethische Überlegungen mit den Daten und Empfehlungen der KI verbindet. Unternehmensbeispiele zeigen, dass KI dieses Urteilsvermögen unterstützen, aber nicht ersetzen kann: Bei Intel erhält das mittlere Management etwa KI-gestützte Hinweise zur Mitarbeiterentwicklung, doch betont der Personalvorstand, dass Qualitäten wie Empathie, Vertrauen und die Schaffung psychologischer Sicherheit einzigartig menschliche Beiträge sind, die die KI nicht leisten kann. Folglich lautet das Credo: Generative KI verschafft Managern mehr Freiraum für anspruchsvollere Tätigkeiten und bessere informierte Entscheidungen, aber sie entbindet nicht von der Verantwortung, diese Entscheidungen reflektiert und werteorientiert zu treffen.

\subsection{Wahrnehmungsabhängige Wirkungen von KI: Unterstützung vs. Kontrolle}

Die Wirkung der Nutzung generativer KI in Organisationen ist stark davon abhängig, wie Führungskräfte und Mitarbeitende die Technologie wahrnehmen und interpretieren. Generative KI kann entweder als hilfreiches Unterstützungsinstrument gesehen werden – oder als Bedrohung, Überwachungswerkzeug bzw. Eingriff von \glqq Maschinen in die Autonomie\grqq{} des Menschen. Solche subjektiven Deutungen beeinflussen maßgeblich Akzeptanz, Arbeitsmotivation und letztlich auch die Erfolgsauswirkungen der KI-Einführung. Die Organisationsforschung beschreibt hierzu ein Spektrum an psychologischen Reaktionen: von Neugier und Zuversicht auf der einen Seite bis zu Skepsis, Angst und Widerstand auf der anderen.

Ein zentraler Faktor ist die Angst vor Kontrollverlust oder Arbeitsplatzverlust. Viele Beschäftigte hegen diffuse Befürchtungen, KI könnte ihre Rolle entwerten oder ersetzen. Bankins et al. (2024) fassen eine Reihe von Studien zusammen, die zeigen, dass solche \textit{fear-based} Einstellungen mit negativen Folgen einhergehen : Wer befürchtet, durch KI \glqq wegrationalisiert\grqq{} zu werden oder dessen Fähigkeiten obsolet werden, reagiert häufig mit innerem Widerstand, sinkender organisationaler Verbundenheit und geringerer Bereitschaft, sich auf die Technik einzulassen. Konkret wurden etwa gesteigerte Jobunsicherheit, abnehmendes Engagement und erhöhte Wechselabsichten bei Mitarbeitern mit starker KI-Angst dokumentiert. Diese Angst kann dabei verschiedene Facetten haben: die Sorge, dass KI den eigenen Job direkt übernimmt; die Befürchtung, langfristig den Anschluss zu verlieren, weil die eigenen Skills neben der KI an Wert verlieren; oder Unbehagen, weil KI-gestützte Arbeitsprozesse als entfremdend und unberechenbar erlebt werden.

Dem gegenüber stehen positive bzw. chancenorientierte Wahrnehmungen von KI. Viele Führungskräfte und Mitarbeiter erkennen durchaus die entlastenden und unterstützenden Möglichkeiten generativer KI und begrüßen diese. So können parallel zur Angst auch optimistische Erwartungen bestehen – etwa die Hoffnung, dass KI lästige Routinearbeiten abnimmt, neue interessante Aufgaben schafft oder zu besseren Entscheidungen führt. Koo et al. (2021) zeigten in qualitativen Interviews, dass Arbeitnehmer oft ambivalente Einstellungen entwickeln: Einerseits sehen sie, dass KI ihre Arbeit erleichtern und sogar neue, sinnvollere Aufgaben generieren kann, andererseits haben sie gleichzeitig die Befürchtung, durch eben diese KI irgendwann überflüssig zu werden. Ein solches Nebeneinander von Zutrauen und Misstrauen wird auch im \textit{Integrated AI Acceptance–Avoidance Model} beschrieben. Dieses Modell besagt, dass Individuen stets die potenziellen Vorteile der KI (z.,B. Leistungssteigerung, Arbeitserleichterung) gegen die potenziellen Nachteile oder Risiken (z.,B. Stress, Fehleranfälligkeit, Kontrollverlust) abwägen. Je nachdem, welche Seite überwiegt, resultiert daraus entweder eine Akzeptanz der Technologie oder ein Vermeidungsverhalten.

Entscheidend ist daher, welche Rahmenbedingungen und persönlichen Voraussetzungen die Wahrnehmung der KI-Nutzung prägen. Auf individueller Ebene spielen etwa Persönlichkeit und Kontrollüberzeugungen eine Rolle: Personen mit hoher innerer Kontrollorientierung und Zuversicht in die eigene Lernfähigkeit tendieren dazu, neue Technologien eher als \glqq Herausforderung\grqq{} denn als Bedrohung wahrzunehmen. Eine Studie von Ding (2021) zeigt beispielsweise, dass Mitarbeiter, die den Einsatz von KI als Challenge statt als Hindrance (Hürde) einstufen, aktivere Bewältigungsstrategien entwickeln und produktiver mit der Veränderung umgehen. Solche Personen suchen gezielt nach Weiterbildung, um sich neue Fähigkeiten im Umgang mit KI anzueignen, und können der Technologie positive Seiten abgewinnen (etwa neue Lernchancen), anstatt sich nur bedroht zu fühlen. Auf organisationaler Ebene kommt es darauf an, wie die Einführung von generativer KI kommuniziert und gestaltet wird. Ein partizipativer Ansatz, bei dem Mitarbeitende frühzeitig eingebunden, geschult und unterstützt werden, fördert Vertrauen und das Gefühl, die KI als nützliches Werkzeug kontrollieren zu können. Eine Kultur, die Autonomie und Lernen betont (High-Performance-Work-Systeme mit Lernkultur), reduziert nachweislich die Ängste der Beschäftigten vor neuen Technologien. Hingegen kann ein autoritärer, rein kostenorientierter Implementierungsstil – bei dem KI möglicherweise als reines Kontrollinstrument zur Überwachung von Leistung eingeführt wird – die Unsicherheit und Ablehnung verstärken. Lingmont und Alexiou (2020) fanden etwa, dass ein durch top-down-Druck geprägtes Klima die Jobangst in KI-Transformationsprozessen erhöht. Mit anderen Worten: Ob generative KI letztlich als \glqq Helfer\grqq{} oder \glqq Aufpasser\grqq{} wahrgenommen wird, hängt stark vom sozialen Kontext ab, in den sie eingebettet ist.

Ein Blick auf extreme Kontexte wie die Plattformökonomie verdeutlicht die Bandbreite dieser Wahrnehmungen. In der Gig-Economy wird durch \textit{algorithmisches Management} bereits vieles von Software vorgegeben: Apps und KI-Systeme verteilen Aufträge, überwachen Arbeitsleistungen und geben automatisiert Rückmeldungen. Studien zeigen, dass viele Gig-Worker diese allgegenwärtige KI-Steuerung als entmenschlichend erleben – sie fühlen sich einem unsichtbaren, unpersönlichen „Algorithmus-Chef“ unterworfen. Berichtet werden Gefühle von Ohnmacht, sozialer Isolation, erhöhter Arbeitsintensität und Stress unter solchen Bedingungen. Gleichzeitig gibt es aber auch positive Narrative: Einige Plattformanbieter rahmen ihre KI-gestützten Systeme bewusst als Unterstützung für die Freelancer, indem sie z.,B. die zeitliche Flexibilität und Eigenständigkeit betonen („Sei dein eigener Chef“). Diese Art des Framings kann dazu führen, dass Beschäftigte die algorithmischen Vorgaben als fair und hilfreich akzeptieren, anstatt sie als Fremdkontrolle abzulehnen. So zeigen Galière (2020) und Veen et al. (2020), dass Plattformarbeiter unter bestimmten Bedingungen durchaus agency entwickeln und die KI-Regeln zu ihrem Vorteil nutzen können – etwa indem sie Gamification-Elemente annehmen oder bewusst bestimmte Leistungsmetriken optimieren. Die Lektion daraus für traditionelle Organisationen lautet: Technologie ist formbar durch Wahrnehmung. Auch generative KI in Unternehmen kann entweder Empowerment bewirken oder Widerstände hervorrufen, je nachdem ob sie als Werkzeug zur Unterstützung eigenverantwortlicher Arbeit oder als Mittel strikter Verhaltenskontrolle empfunden wird.

Für das mittlere Management bedeutet dies, dass seine Rolle in der Einführung generativer KI doppelt herausfordernd ist. Zum einen sollen Mittelmanager die KI selbst produktiv nutzen, zum anderen müssen sie als \glqq Translatoren\grqq{} zwischen Technologie und Belegschaft agieren, um die Akzeptanz im Team zu fördern. Ihre eigene Einstellung gegenüber der KI strahlt dabei auf ihre Mitarbeiter aus. Wenn ein Abteilungsleiter die KI proaktiv als Hilfsmittel zur Verbesserung der Teamleistung darstellt (\glqq KI hilft uns, lästige Aufgaben schneller zu erledigen, damit wir uns spannenderen Projekten widmen können\grqq{}), werden Unterstellte die Neuerung eher positiv aufnehmen. Vermittelt der Manager jedoch (direkt oder indirekt) den Eindruck, die KI diene vor allem dazu, Mitarbeiter zu überwachen oder ihre Fehler aufzudecken, ist Misstrauen vorprogrammiert. Entsprechend heben neuere Studien hervor, dass Führungskräfte eine kritische Rolle als Change Agents in KI-Projekten spielen. Ihre Kommunikation und ihr Verhalten rahmen die Technologie für die Belegschaft. Praktisch empfiehlt es sich, generative KI im Sinne eines \textit{Enabling Tools} einzuführen: Mittelmanager sollten klar vermitteln, dass die KI zur Unterstützung der Entscheidungsfindung und zur Entlastung bei Routineaufgaben dient – nicht als Ersatz für menschliche Kompetenz und schon gar nicht als \glqq Big Brother\grqq{}-Überwachung. Indem man Erfolge durch die KI-Nutzung hervorhebt (z.,B. bessere Entscheidungen, Zeitersparnis) und gleichzeitig die unersetzlichen menschlichen Beiträge würdigt (z.,B. Urteilsvermögen, Kreativität, Empathie), entsteht ein Klima, in dem die Technologie als Chance begriffen wird. Zentral ist zudem, Raum für Fragen und Bedenken zu geben, um subjektive Befürchtungen abzubauen. Dies deckt sich mit Befunden, wonach Vertrauen und Ease of Use Schlüsselfaktoren für positive Einstellungen sind. Fühlen sich Mitarbeiter sicher im Umgang mit der KI und erleben sie diese als nützlich, steigt die Nutzungsbereitschaft nahezu zwangsläufig. Insgesamt zeigen die theoretischen und empirischen Einsichten: Generative KI entfaltet in der Entscheidungsarbeit des mittleren Managements ihr positives Potenzial vor allem dann, wenn sie als Kooperationspartner wahrgenommen wird – als intelligentes Werkzeug, das menschliche Entscheidungsprozesse unterstützt und verbessert. Gelingen Führungskräften diese integrative Sicht und eine entsprechend partizipative Umsetzung, so ist die Einführung generativer KI nicht nur technologisch, sondern auch organisatorisch \textit{anschlussfähig} und kann nachhaltige Verbesserungen in Entscheidungsqualität und -akzeptanz bewirken.

\bigskip

Fazit: Die Nutzung generativer KI in organisationellen Entscheidungsprozessen des mittleren Managements lässt sich theoretisch als \textit{sozio-technisches Phänomen} verorten. Generative KI ist eine neue Klasse von Arbeitssystemen, die – im Unterschied zu früherer Automatisierung – vornehmlich eine \textit{augmentierende} Rolle spielt und menschliche Urteilskraft ergänzt, anstatt sie zu ersetzen. In der Entscheidungsvorbereitung entlastet sie Manager von Routineanalysen und liefert vielfältige Entscheidungshilfen, was die Managerrolle hin zu höherwertigen Tätigkeiten und hybriden Mensch-KI-Rollen verschiebt. Ob diese Entwicklung positiv verläuft, hängt jedoch wesentlich von den Wahrnehmungen und Deutungen der beteiligten Menschen ab: Wird KI als Unterstützung und Chance begriffen, kann sie die Effektivität und Qualität von Entscheidungen steigern; wird sie hingegen als Kontrollinstrument oder Bedrohung empfunden, drohen Ablehnung und negative Folgewirkungen auf Motivation und Vertrauen. Theoretisch anschlussfähig ist diese Analyse an Konzepte der Organisationsentwicklung, die Technologieeinführungen als einen Prozess der gemeinsamen Sinnstiftung (\textit{Sensemaking}) und Anpassung betrachten: Die unabhängige Variable \glqq Nutzung generativer KI in der Entscheidungsvorbereitung\grqq{} ist nicht isoliert-technisch zu verstehen, sondern nur in ihrem organisatorischen Kontext adäquat – als ein Bündel von technischen Möglichkeiten, neuen Arbeitspraktiken und subjektiven Interpretationen. Entsprechend kommt es in der Praxis darauf an, Gestaltungsspielräume zu nutzen: Durch partizipative Implementierung, Qualifizierung und kulturelle Begleitung kann generative KI so in die Entscheidungsarbeit integriert werden, dass sie tatsächlich als augmentierendes Werkzeug wahrgenommen wird und mittlere Manager in die Lage versetzt, bessere Entscheidungen mit KI-Unterstützung zu treffen, ohne ihre menschliche Autorität und Verantwortung einzubüßen. Dies gewährleistet theoretisch wie praktisch die Anschlussfähigkeit der Technologie an zentrale Ziele der Organisationsentwicklung, nämlich Effizienzsteigerung bei gleichzeitiger Befähigung und Einbindung der Mitarbeitenden.